{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_tutorial.ipynb",
      "provenance": [
        {
          "file_id": "13OlNjwyQrTdDQ715D5QcU4XQs14tVRdD",
          "timestamp": 1641900346812
        },
        {
          "file_id": "1ZvJQnDahFXwCbxbEyc3QG_72_4iZDwUe",
          "timestamp": 1637862754194
        }
      ],
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q810J1oD2ePl"
      },
      "source": [
        "# Training a model\n",
        "\n",
        "We start this tutorial on influence functions with training a classification model on MNIST. We follow the example from the [Flax](https://flax.readthedocs.io/en/latest/) library. For convenience we reproduce the training code in this colab so you can follow it step by step. We have modified the code to illustrate how to use multiple accelerators, i.e. we work with `jax.lax.pmap` instead of `jax.jit`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "![ -d jax_influence ] || git clone --depth=1 https://github.com/google-research/jax_influence\n",
        "!cd jax_influence && git pull\n",
        "# Follow the installation instructions in pip_package/"
      ],
      "metadata": {
        "id": "sVB3Q-_ii_tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jax_influence import batch_utils"
      ],
      "metadata": {
        "id": "QBKDpLb8jvKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw7nbDFc2coo"
      },
      "source": [
        "from flax import linen as nn\n",
        "import flax\n",
        "from flax.metrics import tensorboard\n",
        "from flax.training import train_state\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import ml_collections\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F1vkX37t3Hh"
      },
      "source": [
        "# Enable eager exeuction and mask accelerators from TensorFlow.\n",
        "# We use TensorFlow only for the data pipeline.\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "tf.config.experimental.set_visible_devices([], 'GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT45KGNj4WZZ"
      },
      "source": [
        "#@title Directory for training.\n",
        "workdir = 'flax_mnist_training' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DPvgIqc0zJ9"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"A simple CNN model.\"\"\"\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    x = nn.log_softmax(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def cross_entropy_loss(logits, labels):\n",
        "  return -jnp.mean(jnp.sum(labels * logits, axis=-1))\n",
        "\n",
        "\n",
        "def per_example_cross_entropy_loss(logits, labels):\n",
        "  xentropy = jnp.sum(labels * logits, axis=-1)\n",
        "  return xentropy\n",
        "\n",
        "\n",
        "def compute_metrics(logits, labels):\n",
        "  one_hot = jax.nn.one_hot(labels, 10)\n",
        "  loss = cross_entropy_loss(logits, one_hot)\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "  metrics = {\n",
        "      'loss': loss,\n",
        "      'accuracy': accuracy,\n",
        "  }\n",
        "  return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMroLr_S3Hm-"
      },
      "source": [
        "def apply_model(state, images, labels):\n",
        "  \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
        "  one_hot = jax.nn.one_hot(labels, 10)\n",
        "  def loss_fn(params):\n",
        "    logits = CNN().apply({'params': params}, images)\n",
        "    loss = cross_entropy_loss(logits=logits, labels=one_hot)\n",
        "    return loss, logits\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (_, logits), grads = grad_fn(state.params)\n",
        "  grads = jax.lax.pmean(grads, 'batch')\n",
        "  metrics = compute_metrics(logits, labels)\n",
        "  metrics = jax.tree_map(lambda x: jax.lax.pmean(x, 'batch'), metrics)\n",
        "  return grads, metrics['loss'], metrics['accuracy']\n",
        "\n",
        "def update_model(state, grads):\n",
        "  return state.apply_gradients(grads=grads)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4CbWo-W31ll"
      },
      "source": [
        "def train_epoch(state, train_ds, batch_size, rng):\n",
        "  \"\"\"Train for a single epoch.\"\"\"\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, len(train_ds['image']))\n",
        "  perms = perms[:steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "\n",
        "  epoch_loss = []\n",
        "  epoch_accuracy = []\n",
        "\n",
        "  for perm in perms:\n",
        "    batch = {'image': train_ds['image'][perm, ...], 'label': train_ds['label'][perm, ...]}\n",
        "    batch = batch_utils.shard(batch)\n",
        "    grads, loss, accuracy = jax.pmap(apply_model, axis_name='batch')(state, batch['image'], batch['label'])\n",
        "    state = jax.pmap(update_model, axis_name='batch')(state, grads)\n",
        "    epoch_loss.append(loss)\n",
        "    epoch_accuracy.append(accuracy)\n",
        "  train_loss = np.mean(epoch_loss)\n",
        "  train_accuracy = np.mean(epoch_accuracy)\n",
        "  return state, train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def get_datasets():\n",
        "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
        "  ds_builder = tfds.builder('mnist')\n",
        "  ds_builder.download_and_prepare()\n",
        "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
        "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
        "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
        "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
        "  return train_ds, test_ds\n",
        "\n",
        "\n",
        "def create_train_state(rng, config):\n",
        "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
        "  cnn = CNN()\n",
        "  params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
        "  tx = optax.sgd(config.learning_rate, config.momentum)\n",
        "  return train_state.TrainState.create(\n",
        "      apply_fn=cnn.apply, params=params, tx=tx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSNv2ZY14BDe"
      },
      "source": [
        "def train_and_evaluate(config: ml_collections.ConfigDict,\n",
        "                       workdir: str) -> train_state.TrainState:\n",
        "  \"\"\"Execute model training and evaluation loop.\n",
        "\n",
        "  Args:\n",
        "    config: Hyperparameter configuration for training and evaluation.\n",
        "    workdir: Directory where the tensorboard summaries are written to.\n",
        "\n",
        "  Returns:\n",
        "    The train state (which includes the `.params`).\n",
        "  \"\"\"\n",
        "  train_ds, test_ds = get_datasets()\n",
        "  rng = jax.random.PRNGKey(0)\n",
        "\n",
        "  summary_writer = tensorboard.SummaryWriter(workdir)\n",
        "  summary_writer.hparams(dict(config))\n",
        "\n",
        "  rng, init_rng = jax.random.split(rng)\n",
        "  state = create_train_state(init_rng, config)\n",
        "  state = flax.jax_utils.replicate(state)\n",
        "  test_batch = {'image':  test_ds['image'], 'label':  test_ds['label']}\n",
        "  test_batch = batch_utils.shard(test_batch)\n",
        "  for epoch in range(1, config.num_epochs + 1):\n",
        "    rng, input_rng = jax.random.split(rng)\n",
        "    state, train_loss, train_accuracy = train_epoch(state, train_ds,\n",
        "                                                    config.batch_size,\n",
        "                                                    input_rng)\n",
        "\n",
        "    _, test_loss, test_accuracy = jax.pmap(apply_model, axis_name='batch')(state, test_batch['image'], test_batch['label'])\n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_accuracy = np.mean(test_accuracy)\n",
        "    print(\n",
        "        'epoch:% 3d, train_loss: %.4f, train_accuracy: %.2f, test_loss: %.4f, test_accuracy: %.2f'\n",
        "        % (epoch, train_loss, train_accuracy * 100, test_loss,\n",
        "           test_accuracy * 100))\n",
        "\n",
        "    summary_writer.scalar('train_loss', train_loss, epoch)\n",
        "    summary_writer.scalar('train_accuracy', train_accuracy, epoch)\n",
        "    summary_writer.scalar('test_loss', test_loss, epoch)\n",
        "    summary_writer.scalar('test_accuracy', test_accuracy, epoch)\n",
        "\n",
        "  summary_writer.flush()\n",
        "  return state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ1bil7V5X1P"
      },
      "source": [
        "def get_config():\n",
        "  \"\"\"Get the default hyperparameter configuration.\"\"\"\n",
        "  config = ml_collections.ConfigDict()\n",
        "\n",
        "  config.learning_rate = 0.1\n",
        "  config.momentum = 0.9\n",
        "  config.batch_size = 128\n",
        "  config.num_epochs = 2\n",
        "  return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpwMgPWn5hT7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1641895032023,
          "user_tz": -60,
          "elapsed": 23525,
          "user": {
            "displayName": "Andrea Schioppa",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiW7AK6Z3ln1Mf6p-P9rYBrdplMHJzWkfBJddUXUQ=s64",
            "userId": "15169126470040635187"
          }
        },
        "outputId": "f8708e77-d256-4e8b-f7b5-37e4ecc9a94c"
      },
      "source": [
        "final_state = train_and_evaluate(get_config(), workdir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1, train_loss: 0.2712, train_accuracy: 91.77, test_loss: 0.0639, test_accuracy: 97.83\n",
            "epoch:  2, train_loss: 0.0505, train_accuracy: 98.43, test_loss: 0.0387, test_accuracy: 98.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_udWst05lqT"
      },
      "source": [
        "unrep_state = flax.jax_utils.unreplicate(final_state)\n",
        "with tf.io.gfile.GFile(os.path.join(workdir, 'trained_params.flax'), 'wb') as f:\n",
        "  f.write(flax.serialization.to_bytes(unrep_state.params)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC4ljHKSw0vW"
      },
      "source": [
        "# Running the Arnoldi Iteration\n",
        "\n",
        "In this step we run the Arnoldi Iteration on the MNIST data. We will load the trained model and distill the top 100 projectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RVBfTvQyfjO"
      },
      "source": [
        "from jax_influence import arnoldi\n",
        "from jax_influence import batch_utils\n",
        "\n",
        "from jax_influence import linalg_utils\n",
        "from jax_influence import function_factory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_tTG2c4x3nl"
      },
      "source": [
        "# We first create an infinite iterator for the training dataset.\n",
        "@tf.function\n",
        "def normalize_image(record):\n",
        "  out = record.copy()\n",
        "  out['image'] = tf.cast(out['image'], 'float32') / 255.\n",
        "  return out \n",
        "\n",
        "train_it = iter(tfds.builder('mnist').as_dataset(split='train').map(normalize_image).repeat().batch(256*10))\n",
        "# Here we take care of converting tf.Tensor to jnp.array.\n",
        "train_it = batch_utils.BatchIterator(train_it, [batch_utils.maybe_convert_to_array])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmH8_UL66O6d"
      },
      "source": [
        "# Load trained parameters.\n",
        "with tf.io.gfile.GFile(os.path.join(workdir, 'trained_params.flax'), 'rb') as f:\n",
        "  params = flax.serialization.msgpack_restore(f.read())\n",
        "  # Flax likes the parameters to be stored in a Frozen dictionary.\n",
        "  params = flax.core.FrozenDict(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq_x0uXzyWH5"
      },
      "source": [
        "# We now need to define a loss function to be used to estimate the model's\n",
        "# Hessian.\n",
        "def loss_fn(params, batch):\n",
        "  labels = batch['label']\n",
        "  images = batch['image']\n",
        "  one_hot = jax.nn.one_hot(labels, 10)\n",
        "  logits = CNN().apply({'params': params}, images)\n",
        "  loss = cross_entropy_loss(logits=logits, labels=one_hot)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhU4QNm-zTur"
      },
      "source": [
        "# Create the HVP (Hessian-Vector Product) estimator.\n",
        "\n",
        "# First create the HVP step on a single batch.\n",
        "# Here we do the full model parameters so we pass params_select_fn=None.\n",
        "# Set the mean_across_hosts to True as we write code for multiple devices.\n",
        "hvp_step = function_factory.create_hvp_on_sample(loss_fn, mean_across_hosts=True)\n",
        "# A batch consists of 2560 images but to make the computation less intensive we\n",
        "# split it into 10 micro batches.\n",
        "hvp_step = function_factory.create_accumulator(hvp_step, num_micro_batches=10, do_average=True)\n",
        "hvp_step = jax.pmap(hvp_step, 'batch')\n",
        "# To create the estimator we now take the step, and bind the parameters and the training data iterator.\n",
        "hvp_est_fn = function_factory.create_hvp_estimator(hvp_step, handle_p_mapping=True, params=params, data_iterator=train_it)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uedOZCZ3XF8"
      },
      "source": [
        "# Create a random vector to start the Arnoldi iteration.\n",
        "start_params = linalg_utils.random_initialization(params, seed=jax.random.PRNGKey(12))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kY8y8E7zpuG"
      },
      "source": [
        "# Perform the Arnoldi iteration; we save the intermediate results on the host RAM in order to not\n",
        "# fill the accelerators RAM, hence move_to_host=True.\n",
        "arnoldi_result = arnoldi.arnoldi_iter(hvp_est_fn, linalg_utils.inner_product, params, n_iters=200, move_to_host=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIVRNH4N3yW5"
      },
      "source": [
        "# Distill the result of the Arnoldi iteration into eigenvalues and eigenvectors.\n",
        "eigens = arnoldi.distill(arnoldi_result, top_k=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dmeek2n5Bgj"
      },
      "source": [
        "# Save the distilled eigenvalues/vectors.\n",
        "with tf.io.gfile.GFile(os.path.join(workdir, 'projectors.flax'), 'wb') as f:\n",
        "  f.write(flax.serialization.to_bytes(eigens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8dlsDatwz7e"
      },
      "source": [
        "# Influence estimation\n",
        "In this step we show how to use the obtained projectors to compute influence. We consider two cases: self-influence for the test data and influence of the training data on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9bnugAa29ED"
      },
      "source": [
        "from jax_influence import utils\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWtilO_NwzSr"
      },
      "source": [
        "# (Re)-load trained parameters.\n",
        "with tf.io.gfile.GFile(os.path.join(workdir, 'trained_params.flax'), 'rb') as f:\n",
        "  params = flax.serialization.msgpack_restore(f.read())\n",
        "  # Flax likes the parameters to be stored in a Frozen dictionary.\n",
        "  params = flax.core.FrozenDict(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7fsnAQN8qVV"
      },
      "source": [
        "train_ds, test_ds = get_datasets()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmOOJKF2xoyN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1641895484520,
          "user_tz": -60,
          "elapsed": 996,
          "user": {
            "displayName": "Andrea Schioppa",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiW7AK6Z3ln1Mf6p-P9rYBrdplMHJzWkfBJddUXUQ=s64",
            "userId": "15169126470040635187"
          }
        },
        "outputId": "0aeabca3-1c37-4720-abb2-95359b627424"
      },
      "source": [
        "# We corrupt about 20% of the labels in the test dataset.\n",
        "seed = jax.random.PRNGKey(15)\n",
        "seed1, seed2 = jax.random.split(seed)\n",
        "flip_label = jax.random.uniform(seed1, test_ds['label'].shape) < .23\n",
        "random_label = jax.random.choice(seed2, a=10, shape=test_ds['label'].shape)\n",
        "new_label = jnp.where(flip_label, random_label, test_ds['label'])\n",
        "new_label = np.array(new_label)\n",
        "is_mislabeled = (new_label != test_ds['label']).astype('int32')\n",
        "print('% of mislabeled data:', np.mean(is_mislabeled))\n",
        "test_ds['label'] = new_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of mislabeled data: 0.2068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSC72-673i7Q"
      },
      "source": [
        "# We load the projections from the previous step and use the top 20 eigenvalues.\n",
        "# We discard negative eigenvalues sorting on the value instead of the absolute value: use_abs=False.\n",
        "eigval, eigvec = utils.get_eigvals_eigvecs(os.path.join(workdir, 'projectors.flax'), eigvals_slice=(0,20), use_abs=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ozfD6N7xt59"
      },
      "source": [
        "# We now need to define a loss function which is per_example.\n",
        "def per_example_loss_fn(params, batch):\n",
        "  labels = batch['label']\n",
        "  images = batch['image']\n",
        "  one_hot = jax.nn.one_hot(labels, 10)\n",
        "  logits = CNN().apply({'params': params}, images)\n",
        "  loss = per_example_cross_entropy_loss(logits=logits, labels=one_hot)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7J4NxlLyuuv"
      },
      "source": [
        "# To compute the projections we need to construct the Jacobian-Vector Product (JVP) function on each example.\n",
        "jvp_fn = function_factory.create_jvp_on_each_example(per_example_loss_fn)\n",
        "jvp_fn = jax.pmap(jvp_fn, axis_name='batch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRnV1ATK5b9n"
      },
      "source": [
        "train_ds_sharded = batch_utils.shard(train_ds)\n",
        "test_ds_sharded = batch_utils.shard(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDL3WDVN6PDA"
      },
      "source": [
        "eigvec_rep = flax.jax_utils.replicate(eigvec)\n",
        "params_rep = flax.jax_utils.replicate(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se3fz25N6Yre"
      },
      "source": [
        "projections_test = jnp.zeros((test_ds['image'].shape[0], len(eigvec_rep)))\n",
        "for i, eigvec in enumerate(eigvec_rep):\n",
        "  prj = jvp_fn(params_rep, eigvec, test_ds_sharded)\n",
        "  prj = prj.flatten()\n",
        "  projections_test = projections_test.at[:, i].set(prj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuvtEBiY7JQ6"
      },
      "source": [
        "# This code attempts the computation on the full train data. This should work\n",
        "# on TPUv3. If you get OOM errors use the code in next cell.\n",
        "projections_train = jnp.zeros((train_ds['image'].shape[0], len(eigvec_rep)))\n",
        "for i, eigvec in enumerate(eigvec_rep):\n",
        "  prj = jvp_fn(params_rep, eigvec, train_ds_sharded)\n",
        "  prj = prj.flatten()\n",
        "  projections_train = projections_train.at[:, i].set(prj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf3ykNoCHpy6"
      },
      "source": [
        "# The code here assumes train_ds will be split into batches. Use this code\n",
        "# if your accelerator memory is not enought to process the whole train data.\n",
        "num_splits = 5\n",
        "split_size = train_ds['image'].shape[0]//num_splits\n",
        "projections_train = [jnp.zeros((split_size, len(eigvec_rep))) for _ in range(num_splits)]\n",
        "for split in range(num_splits):\n",
        "  for i, eigvec in enumerate(eigvec_rep):\n",
        "    min_idx = split * split_size\n",
        "    max_idx = (split+1)*split_size\n",
        "    sliced = jax.tree_map(lambda x: x[:,min_idx:max_idx], train_ds_sharded)\n",
        "    prj = jvp_fn(params_rep, eigvec, sliced)\n",
        "    prj = prj.flatten()\n",
        "    projections_train[split] = projections_train[split].at[:, i].set(prj)\n",
        "projections_train = np.concatenate(projections_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUvc5QrV7QFz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1641895509515,
          "user_tz": -60,
          "elapsed": 82,
          "user": {
            "displayName": "Andrea Schioppa",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiW7AK6Z3ln1Mf6p-P9rYBrdplMHJzWkfBJddUXUQ=s64",
            "userId": "15169126470040635187"
          }
        },
        "outputId": "6d96317c-a143-445e-958f-f31a6ffb62db"
      },
      "source": [
        "# Let us try to see how well self-influence performs at recalling the mislabeled points.\n",
        "self_influence = jnp.einsum('bd,d,bd -> b', projections_test, 1.0/eigval, projections_test)\n",
        "print('Self-influence AUC:', metrics.roc_auc_score(is_mislabeled, self_influence))\n",
        "print('Self-influece AP:', metrics.average_precision_score(is_mislabeled, self_influence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-influence AUC: 0.9975904350421524\n",
            "Self-influece AP: 0.9868385708937291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlGE-dyD7l04"
      },
      "source": [
        "# Let us pick a mislabeled test point.\n",
        "# Here we normalize the influence by the projections norm as discussed in the\n",
        "# paper.\n",
        "test_id = np.where(is_mislabeled)[0][45]\n",
        "norm = jnp.einsum('bi,bi->b', projections_train, projections_train)\n",
        "norm = jnp.sqrt(1/(norm+1e-6))\n",
        "influence_norm = jnp.einsum('b, bi,i,i->b', norm, projections_train, projections_test[test_id], 1/eigval)\n",
        "proponents = jnp.argsort(-influence_norm)[:10]\n",
        "opponents = jnp.argsort(influence_norm)[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adTuPkUG8Hh5"
      },
      "source": [
        "def show_image(img, ax=None, title=None, cmap=None, fontsize=12):\n",
        "  \"\"\"Shows a single image.\"\"\"\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "  ax.imshow(img[...], cmap=cmap)\n",
        "  if title:\n",
        "    ax.set_xlabel(title, fontsize=fontsize)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvfOHNBX_M_Y"
      },
      "source": [
        "def show_image_list(list_images, explain_image, list_titles=None, grid=False, figsize=(15, 20), fontsize=14, \n",
        "                    cols = [\"Proponents\", \"Opponents\"]):\n",
        "    '''\n",
        "    Shows a grid of images, where each image is a Numpy array. The images can be either\n",
        "    RGB or grayscale.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    images: list\n",
        "        List of the images to be displayed.\n",
        "    list_titles: list or None\n",
        "        Optional list of titles to be shown for each image.\n",
        "    grid: boolean\n",
        "        If True, show a grid over each image\n",
        "    num_cols: int\n",
        "        Number of columns to show.\n",
        "    figsize: tuple of width, height\n",
        "        Value to be passed to pyplot.figure()\n",
        "    fontsize: int\n",
        "        Fontsize.\n",
        "    '''\n",
        "\n",
        "\n",
        "    def retrieve_image(img_id, is_test=False):\n",
        "      data = train_ds\n",
        "      if is_test:\n",
        "        data = test_ds\n",
        "      return data['image'][img_id]\n",
        "\n",
        "    def retrieve_title(img_id, is_test=False):\n",
        "      data = train_ds\n",
        "      if is_test:\n",
        "        data = test_ds\n",
        "      return str(data['label'][img_id])\n",
        "\n",
        "    num_cols  = len(list_images)\n",
        "    num_rows  = len(list_images[0])\n",
        "\n",
        "    # Create a grid of subplots.\n",
        "    fig, axes = plt.subplots(num_rows, num_cols+1, figsize=figsize)\n",
        "    show_image(retrieve_image(explain_image, is_test=True), ax=axes[int(num_rows/2), 0], title=None, cmap=\"Greys\")\n",
        "    axes[int(num_rows/2), 0].set_title(\"Image to explain: \" + retrieve_title(explain_image, is_test=True), fontsize=fontsize)\n",
        "    axes[int(num_rows/2), 0].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n",
        "    axes[int(num_rows/2), 0].grid(grid)\n",
        "    axes[int(num_rows/2), 0].set_aspect('equal')\n",
        "    for i in range(num_rows):\n",
        "      if i is not int(num_rows/2):\n",
        "        axes[i, 0].set_visible(False)\n",
        "\n",
        "    for ax, col in zip(axes[0][1:], cols):\n",
        "      ax.set_title(col, fontsize=fontsize)\n",
        "\n",
        "    axes[0,1].set_ylabel(\"Top 1\", rotation=0, fontsize=fontsize, labelpad = 100)\n",
        "    axes[num_rows-1,1].set_ylabel(\"Top 5\", rotation=0, fontsize=fontsize, labelpad = 100)\n",
        "\n",
        "    for i in range(num_rows):\n",
        "      for j in range(num_cols):\n",
        "\n",
        "          img    = list_images[j][i]\n",
        "          cmap = \"Blues\"\n",
        "          if j >= 1:\n",
        "            cmap = \"Reds\"\n",
        "          \n",
        "          show_image(retrieve_image(img), ax=axes[i, j+1], title=retrieve_title(img), cmap=cmap, fontsize=fontsize)\n",
        "          axes[i, j+1].tick_params(axis='both', which='both', bottom=False, left = False, top=False, labelbottom=False, labelleft = False)\n",
        "         \n",
        "          axes[i, j+1].grid(grid)\n",
        "          axes[i, j+1].set_aspect('equal')\n",
        "        # Create list of axes for easy iteration.\n",
        "    if isinstance(axes, np.ndarray):\n",
        "        list_axes = list(axes.flat)\n",
        "    else:\n",
        "        list_axes = [axes]\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "    plt.savefig('proponents_opponents.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "height": 1000
        },
        "id": "cPrR-ilU_2Mo",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1641895523832,
          "user_tz": -60,
          "elapsed": 1007,
          "user": {
            "displayName": "Andrea Schioppa",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiW7AK6Z3ln1Mf6p-P9rYBrdplMHJzWkfBJddUXUQ=s64",
            "userId": "15169126470040635187"
          }
        },
        "outputId": "6cbbd4db-cf5e-495b-a999-8feb0b81282a"
      },
      "source": [
        "list_images = [proponents[:5], opponents[:5]]\n",
        "show_image_list(list_images, test_id)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxcAAARwCAYAAACYdqlQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\nbGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsT\nAAALEwEAmpwYAABPg0lEQVR4nO3dd9hcZZk/8PtOQu8QkKJJEFBRQFSKLKhYEFx1VdRdXUGwoK4i\niGsHlbWsdRURO7ZVxLUhKjZQURFWAQULHSVIJyAQCAGSPL8/ZmDf32ue8yaTJ5m3fD7XNVeY+c45\n544xJ+93zswzWUoJAACAFTVt2AMAAACTg3IBAAA0oVwAAABNKBcAAEATygUAANCEcgEAADShXAAA\nAE0oFwDjTGZ+ITNL/3ZPZv45Mz+YmesMe7ZVJTNPz8zjhj0HTFWZuVVmfjozr8rMuzPz6sz8TGbe\nf9izrSyZOad/3t1l2LNMZMoFwPh0WkRsEREPjIijIuKVEfHB0U/KzBmZmat4NmASy8ytI+KciNgh\nIg6KiG0j4oCIeFhEnJ2Zc4Y3HeOdcgEwPt1VSrmulPLXUspXIuKEiHhmZh6dmX/MzIMz8/KIuCsi\n1snMWZl5UmbO79++NfIVxhHbvTQzr8zMOzPz25k5c8RzpmXmWzPzr5l5V2b+ITOfMSK/91W9Z2fm\nqZm5IDMvyMx9Rg6emQ/NzFP6c9yQmSdm5uYj8i9k5vcy8/D+q6F/y8zPZ+ba9+YR8biIeNWIKzhz\nMnO1zDw2M6/pz/fXzHzvSvrfH6ayj0XEkoh4UinlJ6WUK0spP4uIJ/Uf/1jEfVcYP5mZH+n/Pf5b\nZn4gM+/7+TIzr+iff76cmbdn5nWZ+bqRB1uO89fzMvPy/nP+v/NX/3kv6p+TFmbmJZl5xKhZSma+\nLDO/npl39K8KHzBiF3/p/3p2/7mn97fbMTN/kpm39Y99fmY+vsX/0JORcgEwMdwZEav1/3vriPjX\niHhuRDw8egXj2xFxv4h4QkQ8PiK2jIhvj7qqMSd6rz4+I3o/JGwXEZ8bkR8eEa+PiDdGxI4RcVJE\nfCszdx41y7sj4tj+sc+OiK9m5roREZm5RUT8IiL+GBG79Y+zbkR8Z+Q/8hHxmOi9KvqkiPiXiHhW\n//j3znFWRHw+eldvtoiIv0bEYf3nPa8/+79ExMVd/6MByyczN46I/SLiY6WUBSOz/v2PR8RTMnOj\n/sMviN7Pk3tExMsj4mUR8ZpRu31tRFwYEY+MiLdHxH9m5v7942Us+/nr3nPFkyPiEdE7F9079yER\n8Z8R8baI2D4i/j1657JXjprlbRFxcvTOX/8TEZ/LzNn9bLf+r/tF77yzf//+VyLi2n7+iIg4OiIW\nBktXSnFzc3NzG0e3iPhCRHxvxP3dImJe9P4hPDoi7omI+43I94mIxRExZ8RjD4z/e+Ux+tstjohZ\nI56zV0SUiNiuf//qiHjbqFlOj4gv9/97Tv/5Lx+Rb9V/bK/+/XdExE9G7WOj/nN2G/H7+2tEzBjx\nnM9ExGmjjnvcqP0cGxE/iYgc9p+Rm9tkvUXE7v2/r8+q5M+69+9z/+/pJSP/TkbvbZxXjbh/RUSc\nOmofx0fEGf3/Xtbz18KI2GDEc46MiMtG3L8yIg4cdZzXRMQFI+6XiHjPiPszImJBRBzQv3/vOW6X\nUfu5LSIOGvafzUS5uXIBMD7t138LwcLovYr/i4h4dT+7qpRy/Yjnbh8R15RSrrj3gVLKnyPimoh4\n6IjnXV1KuXLE/V9H7x/w7TNz/ei9WvirUXOcMWofERG/H/Hf1/R/3az/66Mi4rH92W/PzNujVyQi\nIrYZsd0FpZRFo/azWXT7QkTsHBGXZObHMvOpo66GAO2UyuM5Kv/f0v8JvO+siNiqf04Z+ViMun/v\neWVZz19zSym3jrh/3zkjMzeNiAdExKdGnXveG///eSdixPmrfw66McY+93woIo7PzJ9m5pGZ+ZAx\nnj+lzRj2AAAs1S+i9/aCe6L3D+89ERH9dwncMeq5GfUfBGqP1yzt+aMfu+e+oJTSn+neH/KnRcQp\nEfG6+HsjC9E9o7ISY7xVt5Ty2+x9kHS/6L194osRcX5m7lNKWdK1LbDMLo3e38eHRe/tSqNt388v\nb3S8ZT1/dZ0z7v31FRFx5hjHG+Tcc3RmnhART4mIfSPi7Zn5ilLK57q2m6q84gMwPi0opVxWSpl7\nb7HocEH0Ximcc+8DmfnA6F2JuGDE87bKzAeMuL9b9P4duLCUclv0Xgnca9S+9xq1j7H8Nno/lMzt\nzz/yNn859nN3REwf/WApZX4p5eullH+LiKdGr2Rsuxz7BTqUUm6OiB9FxCvvXWThXv37r4qIH/Sf\nFxGx+6jPRjw6ei+I3DbqsRh1/8L+fy/r+atr5uuj97bObZZy3rlsWfbRd3f/16Wdey4tpRxbSnlq\nRHw2Il66HPudUpQLgInvtIg4PyJOyMxHZW+N9hOi94P+T0c8786I+GJm7pyZe0TEJyPilFLKpf38\nAxHxusx8fmY+KDPfEb0PXv/XcszysYjYICL+JzN3z8wHZuaTsrde/nrLsZ8rImK3/ipRM7O3ktVr\n+7Ntn5nbRu9D7bdFxFXLsV9gbIdG790tp2XmEzLzAZm5d0ScGr0rDYeOeO6WEXFMZj44M58TvUUh\nPjxqf4/OzDdn5nb9D16/cMRzlvX8NZajI+IN/RWiHpyZO2TmCzPzzcuxjxuid57cNzPvl5kbZOZa\n/bdh7t0/H+0ey/+iy5SiXABMcP33Oz8zeu8dPj0ifhYR10XEM0e9F/qKiPhqRHw3ev9o/zkiXjQi\nPzZ6BeP90Vvt6VkR8exSynnLMcs1EbFn9D7L8cOI+FP0Csdd/duy+mD0XkW8oP/7mhUR86P3g8tv\noveDx84R8ZQyakUbYMWUUi6PiF2i9/f3S9E7V3wlelcbdi2l/GXE00+I3iv9v47ewgyfjb8vFx+K\niJ0i4ncR8a7oLRzxjf6xlvX8NdbMx0fEiyPiwOiVlV9G762lf+nabtQ+FkVvVbqXRu9K7snR+7D5\nRtF7G+bF0VtF76zorYDFUuRy/LkBMEFl5tER8ZxSyg7DngWYHPrfA/HHUsqhHc+5Inorv/3dl4Ay\nOblyAQAANKFcAAAATXhbFAAA0IQrFwAAQBPKBQAA0IRv6AbGpZkzZ5bZs+cMewwYt+bOvSLmzZuX\nYz+T5TVz5iZlzqxZwx4Dxq0rrrwy5s27aannH+UCGJdmz54Tv/r1OcMeA8atPXffZdgjTFpzZs2K\nc844fdhjwLi1y157VzNviwIAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUC\nAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAu\nAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnl\nAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQ\nLgAAgCaUCwAAoAnlAgAAaGLGsAcAAKCu3HxtNXvDnN2r2Vsfv23nftd54f7VbNrTX1LNcvW1OvfL\n1ObKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0YSlagCnmxxdeV83+5a3fqW849/f1\nLHPgebZ72jOq2amve1w122Dt1QY+JkwkufEW1ezR661ZzT59xl869/sPv/9ENTvxoPdVs3/aZN1q\nttOcDTuPucljt69mueujO7cdRD5018582raPaH7Mqc6VCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQL\nAACgCeUCAABoQrkAAACa8D0XABPQ7QsXVbMfXlz/HouIiMOP/WU12/qhc6rZYW98cjXbZsN1qtn1\nC+7qnOeQl32gvu0hu1cz33MBEU/cafNqdvmlf+vc9pGXnF/N9lh0d33D2+v7XXLSZzqPWS69tJrd\n8ZkTq9mCW++sZjf/rX6O+fMtH+qc5/w7FlazNx3zimo2/YVv6tzvVObKBQAA0IRyAQAANKFcAAAA\nTSgXAABAE8oFAADQhHIBAAA0YSlagHHqjEvnVbOnv/TD1Wz97Xfu3O+P/+Op1Wxa1rf70eU3VrNX\nfuucanb33fVlc4Gxldvq54IPn3VlNfunmet17jendbzGvPqa9WzjLarR9Je8rfOYXdYfMKsvxhux\nfdeSuhHxlBP+q5q96t+Oq2bHXX1VNZvx5vp2U4ErFwAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABA\nE8oFAADQhKVoAcapr//x+nq48PZqdNvvzujc717P7sjX2bAa5Wazq9kjdt+2mv325B93zgN0W3Lm\nKdXs+nvqSz3v/K4XrYxxJpScsXpnPu3AN1azg44+oZq9+/3fq2ZvtxQtAADAilMuAACAJpQLAACg\nCeUCAABoQrkAAACaUC4AAIAmLEULME4dsdecapZvflk1m7Pxmp37/cftNqtm665Z/2dhy43W6txv\nzY433NGZX3XJ3Go2a5O1BzomTCbTnvi8avaJa59a33DdjVfCNJPMkvpSvrctXlzNblm0pL7LP59X\nzaY9cOdlmWpCc+UCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCZ8zwXAODVn\n03Wq2THPfNgqnGTlmrb6GtVszdWnr8JJYHzK1ep/R6IrY2x33FqNTrppfjWbHlnNyt9uXKGRJjpX\nLgAAgCaUCya0zCxj3L6wEo75sMz8Rmb+uX+Mo1sfAwBgIvK2KCa6LUb899Mi4jOjHrtzJRxz7Yi4\nIiK+FRHvWgn7BwCYkFy5YEIrpVx37y0iblnKY8/LzMsy8+7+r4eM3L5/5eHQzDwlMxdk5tzMPGCM\nY55dSnldKeUrEbFgZf3eAAAmGuWCSSsznxURx0XEMRGxQ0R8JCI+nplPH/XU/4iI70TEzhHx6Yj4\n78zcZdVNCgAwOXhbFJPZ6yLiS6WU4/r3L8nMR0XEGyPiuyOe961Syqf6//3uzHx8RLwmIjqvYAAA\n8P9TLpjMto+Iz4167IyI+KdRj521lPtPXVlDAf+/B+84e9gjACyXzTqWyZ7+qH1W4STjj7dFMdmV\nZXwMAIAVpFwwmV0YEXuNemyviLhg1GOPXsr9C1fWUAAAk5W3RTGZfSAivp6Z50bEjyNiv4h4QUTs\nP+p5+2fm2RFxekQ8JyKeGBG713aamatHxEP7d9eMiM0zc+eIuL2UclnL3wAAwESiXDBplVK+nZmv\njt4Hu4+JiLkR8cpSyndHPfXoiHh2RBwbETdGxItKKWd37HrLiPjdiPvbRMTLI+LnEbF3i9kBACYi\n5YJJo5TyjYjIUY99MiI+Ocam15VS9luO41wx+jgAAPjMBQAA0IgrFwCssL/eVP+y+qvO+Hnntq99\n24tbjwOwTBYf9/aBtnvZDps3nmTyUC6Y0kop3t4EANCIt0UBAABNKBcAAEATygUAANCEcgEAADSh\nXAAAAE1YLQqAFfaG715QD7N7UbYDd96q8TQAPeWWGzrzI993ykD73fSpuw603VTgygUAANCEcgEA\nADShXAAAAE0oFwAAQBPKBQAA0IRyAQAANGEpWgCWyT2LllSzH558djXbcMddOvc7Z9N1Bp4JoMvi\nT76zM7918eJqttXq9R+Tp7/mPQPPNNm5cgEAADShXAAAAE0oFwAAQBPKBQAA0IRyAQAANKFcAAAA\nTSgXAABAE77nAoBl8rj3n14Pr7moGn3rw89vPwxAX/nbddXs7e/5zsD7PWyP2dUs11x34P1Odq5c\nAAAATSgXAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATlqIF4D6//cvfqtmF3z6pmj310IOr2SPm\nbLgCEwFElEX3VLMFrzy4mt20aHHnfndZd41qtv43vzfmXPw9Vy4AAIAmlAsAAKAJ5QIAAGhCuQAA\nAJpQLgAAgCaUCwAAoAlL0QJwn9d8/fx6uO7G1egd+z1kJUwD0FOu+GM1+/fv1LNNV5veud8Xnfq5\napZrrTf2YPwdVy4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAlL0QJMMSf+7spq9oeT\nvlPN/usjh1WzB262zgrNBFBuv6Wa/fgJz69m0yOr2RuesG3nMafv9Lgx52L5uHIBAAA0oVwAAABN\nKBcAAEATygUAANCEcgEAADShXAAAAE1YihZgijn6S+fXw3U2qkbP3XGrlTANMJWUJYur2eKPHlXN\nvn3T7dXsH9Zfs5qt962fLNtgNOPKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0oVwA\nAABN+J4LgEnmj3+9tTO/4X9Pr2YvftNLqtl6a6026EgAERGx5JJzqtmh7/p2Ndti9fqPrC/49BtX\nZCQac+UCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJqwFC3AJHPQ8b/ufsL6m1Wjt++z\nXeNpgKmk3P63zvy0Jx880H7333yDajb96YcMtE9WDlcuAACAJpQLAACgCeUCAABoQrkAAACaUC4A\nAIAmlAsAAKAJS9ECTEAXXn1bNfvzj3/Yue0L3/CSarb+WqsNPBMwNZRSqtnCww7q3Pakm+ZXs93W\nW7Oa7XDuL8YejHHBlQsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaMJStAAT0KLF9aUg\nY6MtO7d9534PajwNMJUs+UN9Wdgj/ue3A+/3oC+/o5rl2hsMvF9WLVcuAACAJpQLAACgCeUCAABo\nQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGjC91wATDZ/u6YzPuWia6vZ8x8xq/U0wCQzfafHVbNP3nHV\nKpyE8ciVCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABowlK0ABPQjrM2qGZ/O+tDq3AS\nAPg/rlwAAABNKBcAAEATygUAANCEcgEAADShXAAAAE0oFwAAQBNZShn2DAB/JzNvjIi5w54DxrHZ\npZRNhz3EZOT8A2Oqnn+UCwAAoAlviwIAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AKAqM9fLzGMyc25m\n3pmZZ2bmrsOeC5jcMvOKzCxLuZ0y7NnoNmPYAwAwrh0fETtFxEERcVVEHBARp2XmQ0spVw91MmAy\n2zUipo+4v0VEnBsRXxvOOCwrS9ECsFSZuVZEzI+IZ5dSTh7x+LkR8YNSylFDGw6YUjLzyIh4fURs\nWUpZMOx5qPO2KABqZkTvlcOFox6/MyL2WvXjAFNRZmZEvCQivqxYjH/KBQBLVUqZHxFnRcRRmblV\nZk7PzAMiYo/ovUUBYFXYJyK2jt7bNBnnlAsAuhwYEUui93mLuyLisIg4MSIWD3MoYEo5JCLOLqWc\nN+xBGJtyAUBVKeXyUsrjImLdiHhAKWW3iFgtIv4y3MmAqSAzN4uIZ0TEZ4Y9C8tGuQBgTKWUO0op\n12bmRhGxb0ScPNY2AA0cHL2rpl8d8hwsI6tFAVCVmftG74WoiyJi24j4QPT+od+rlHLPMGcDJrf+\nB7kvjoifl1IOGfY8LBvfcwFAlw0i4j0Rcf+IuDkivhkRRyoWwCqwd0RsF73v12GCcOUCAABowmcu\nAACAJpQLAACgCeUCAABowge6gXFp5syZZfbsOcMeA8atuXOviHnz5uWw55iMZs7cpMyZNWvYY8C4\ndcWVV8a8eTct9fyjXADj0uzZc+JXvz5n2GPAuLXn7rsMe4RJa86sWXHOGacPewwYt3bZa+9q5m1R\nAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCEcgEAADShXAAAAE0oFwAAQBPKBQAA0IRy\nAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCEcgEAADShXAAAAE0o\nFwAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCE\ncgEAADShXAAAAE0oFwAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0oVwAAABN\nzBj2AAC09ebvX9SZH3/Cr6vZc5/1yGr2yt1nVbNrb19YzbbeaJ3OebbdfN3OHICJw5ULAACgCeUC\nAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGjCUrQAE9CvLptXzT75jk92b5z115VOPLa+jO2JC28f\nc66lecbhL+7Mv/CCRwy0X2DiKQturWYLDz2wmi3uWO76Ez+5tJotGWOeVz1xu2q25pP3rGbT//U1\n1SzX3mCMo05urlwAAABNKBcAAEATygUAANCEcgEAADShXAAAAE0oFwAAQBPKBQAA0ITvuQCYgL57\n8Y31cMnizm0//qnXVrNH3G+jarbHM98y5lxLc/LxJ3XmNz/jYdVs43VXH+iYwMqz+NQvV7M7P/ul\nzm1/9qsrqllGVrNHzq5/d8QLtt+smpXSOU6cf/bV1ewrpxxfzY7dYONqNv25r+4+6CTnygUAANCE\ncgEAADShXAAAAE0oFwAAQBPKBQAA0IRyAQAANGEpWoAJaM+OZRk/Nca23zj3umr2/rkXDjbQBver\nZ7de37npmVfMq2ZP22HLweYBoty9sPsJt95Qjc7Y7SnV7PRb7qhmb37pP3Qe8qmnvbOa5ez6stS5\n5jqd+x3UlvfcVc1+vcX21eySd36umm1vKVoAAIAVp1wAAABNKBcAAEATygUAANCEcgEAADShXAAA\nAE1YihZgAtp91ibVbNY+T+3c9qef/tJAx5y2zSOr2dkf+edq9qh/ed9AxwPGtvi3p1WzM599eOe2\n37lpfjV7z2v2qWb/8PyXVrPp2+/ReczxJldbo5rNyPp2P7n21mr2kJuurh9vk62Waa6JzJULAACg\nCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGjCUrQAE9Bm69eXTzz3HU/u3PaPhzy6mv3vNTdX\nswMeOauazV+4qH7ANdftnOdXV95WzZ62w5ad28JUsPiED1SzDx328Wr23G1ndu73fT/8fDWb9uDd\nxh5sCrtwwT3VrNx2UzWzFC0AAMAyUi4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnf\ncwEwycyY3v260c5zNhwo6/Km719UD2/6a+e2e85af6BjwkSz8BX7V7PvfPeP1WzXLTeoZq899pXV\nbPoLXr9sg7FUS0o9e/EWG1azaVvv1H6YCcSVCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUC\nAABowlK0ACyTxR3rMn7zu+evwklgeMqCW6vZ4vcc0bntvN9fXc32f/vzq9n0F76hmuWa63Qek8FN\ny3q23fYzV90gE4wrFwAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhKVoAVgmSzqWol34\nx7PqG667ced+99rako5MIPfcXY1uPfOizk23+tEPqlmu1/33hJVjyZ/Pq2Z/W7Skmq3z8gNWwjST\ngysXAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCEpWgBWHGZ1Wja5lt3brrhOqu3ngZW\nmtxg02q2yU/OXIWT0ML8Qw+vZnust1Y1m/60l6yMcSYFVy4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQ\nLgAAgCaUCwAAoAlL0QKwTK6Yt2Cg7T70749vPAnAsllyzaWd+YfOnFvN3va5N7QeZ0pw5QIAAGhC\nuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJnzPBQDL5NTLbxhou8fN3rTxJADLZsnX\nP9OZ33DP4mo27Un/3HqcKcGVCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABowlK0ACyT\nn19y07BHAPg7S665tJp94T+/2bnt+56wbT1ce4NBR5rSXLkAAACaUC4AAIAmlAsAAKAJ5QIAAGhC\nuQAAAJpQLgAAgCYsRQvAfa6++c5q9uMTT61ma2y/ezXbdP01VmgmgC5LPvtf1WzBktK57bqf/UI1\nyxmrDTrSlObKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0YSlaAO4zf+GienjLtdVo\nnwP3q2brrOGfGmDFLP7JidXsfR/+YTX7p/tt0LnfaZvNHngmls6VCwAAoAnlAgAAaEK5AAAAmlAu\nAACAJpQLAACgCeUCAABowvqAAKywf9xh5rBHACaxa996TDW75q7F1WyHs09vPwydXLkAAACaUC4A\nAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnfcwHAfe64a1E9nLF6Ndp/h61WwjTAVLL4\n6x+tZu86/+pq9sGnPrSa5bobrdBMLD9XLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACg\nCUvRAnCf959+WT3M+utRd9y1uJodcfIFncd86aPuX80eubVlJGGqOO3fP17Ndli7vhT2Wke+eWWM\nw4BcuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJixFC8B97rfhWvXwnoXVaJv9jqpm\nG+y4W+cxP7r/DmPOBUwOi//wy2p25m13VrO3HXNINZv+8Mev0Ey05coFAADQhHIBAAA0oVwAAABN\nKBcAAEATygUAANCEcgEAADRhKVoA7vPmx29bzebe8IJqdunlN1ezX771iZ3HnD4txx4MmBDKvKs6\n84894aBqtmbHuWDa0w8edCRWMVcuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIA\nAGjC91wAcJ8tNlyzmp388kevwkmAiajcNq8zv3jBPdXspVttVM1yk60GnolVy5ULAACgCeUCAABo\nQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGjCUrQAADQx7YE7d+Yfu+Ovq2YQhsaVCwAAoAnlAgAAaEK5\nAAAAmlAuAACAJpQLAACgCeUCAABoIkspw54B4O9k5o0RMXfYc8A4NruUsumwh5iMnH9gTNXzj3IB\nAAA04W1RAABAE8oFAADQhHLB38nMvTOzZObM5djmC5n5vZU5FwAA49uEKBcT/QfXzDw4M28f9hwr\n2eERcUDrnWbmapn5tsy8PDMXZub5mblf6+MAALDiJkS5YPwrpdxaSrllJez6XRHxiog4LCIeGhGf\njIiTMvMRK+FYwCiZuV5mHpOZczPzzsw8MzN3HfZcwOSWmVf030Ux+nbKsGej24QsF/deycjMN2bm\ndZl5a2a+NzOnZebRmXlD//E3jtrutZn5+8y8IzOvzszjM3PDUc95cWZemZkLMvO7mfnKzCyjnvP0\nzDy3/0r6XzLz3Zm5emXWvSPi8xGxzoi/GEf3s40y84uZ+bf+P9qnZebDxvi9r56Z78vMq/q/j7Mz\nc99+lpl5an8/2X9s3cy8NDOPu3ee/gxPy8zz+r+HczPzUR3H3CQzT+wf887M/FNmvmhpfyYj7p+e\nmR/PzP/MzHn9P5MPZuby/n/uwIh4XynllFLKn0spn4iI70fEvy/nfoDBHB8R+0bEQRGxY0T8OCJO\ny8ythjoVMNntGhFbjLg9MiJKRHxtmEMxtglZLvoeGxFbR8Te0Xtl+w3R+6FzjYjYKyKOjoj3jvqh\neUlEvCYiHhYR/xoRu0XER+8NM3OP6P1D+rGI2DkivhMR/zHyoP0f5E+IiOP6+3lxRDwnIv6zMueZ\n/WMuiP/7C/LBfvaFiNg9Ip7Rn2VBRPwwM9fq+H1/PiIe159/x4j4YkR8NzMfXnrrCh/Un/11/ecf\nGxF3R8TrR+3ngxHxxojYJSL+HBGnZObalWOuGRG/jYin9X/PH4mIT2XmEzvmjIh4QUQsioh/iIhD\no/e/w7/cG/aL4FhrIa8REQtHPXZn9P6MgZWofy56dkS8qZRyeinlslLK0RFxWUT821CHAya1UsqN\npZTr7r1FxD9GxG0R8fUhj8ZYSinj/ha9H8K/N+r+XyNi+ojHzomI34/a7oqIeF3HfveLiLsiYlr/\n/okR8cNRz/l073+m++7/IiLeOuo5z4yI26P/vSFLOc7BEXH7qMe2i14Df+yIxzaIiFsj4qWV/WwT\nvYI0a9Tj346Ij4+a566IeGf/14ePyPbuH/cFIx5bNyJuufe4I54zs+N/u69GxPEdf0anR8RZo7Y5\nddQ2h0bERWP82X8lIi6MiAdHrwzvE70Sdtew/3/p5jbZbxGxXv9csO+ox8+IiNOHPZ+bm9vUuEVE\nRu+F0OOGPYvb2LeJfOXiglLK4hH3r4+IP4x6zvURsdm9dzLzCf23DV2VmfMj4lsRsXpEbN5/ykMi\n4jej9vHrUfcfFRFHZubt996i9wPwOiP2syy2j15ROOveB0opt/Z/Dw+tbPPI6P0Fu2DU8Z8aveJx\n736+3Z/pqIg4qpRy/lL2NfK4t3cdNzOnZ+aR/beU3dQ/5v4RMWuM3+PvR92/Jkb8eZRSjiulPGSM\nfRweERdHxAXRuwJzXPSu3izu2ghYcaWU+dE7VxyVmVv1zwUHRMQe0bsKC7Aq7BO9d6scP+xBGNuM\nYQ+wAu4Zdb9UHpsWEZGZsyPilIj4TES8LSJuit4P6ydGr2BE9H5wH+ttOtOi91appV2Wu3EZZ7/3\nWDW1Gab1s13j73+vd96348w1+89ZHBHbLsdMNa+L3mccDo9eCbk9em8D26xro6XMeN+fx7IqpdwY\nEc/s/542iV5BeW9E/GV59gMM7MCI+FxEXBW9c8pvo3fefOQwhwKmlEMi4uxSynnDHoSxTeRysbx2\niV6JOOLeKx6Z+bRRz7kwep99GGn0/d9GxENKKZctx7Hvjojpox67IHo/aO8RvbdaRWauH73PUXy+\nsp/fRa+UbF5K+VnH8T4Qvc8q7BMRP8rM75dSTh71nEdH7xJjZOY6EbFDRPx3ZX97RcR3Sylf6j8/\nI+JB0Xsr1SpRSlkYEVdn5mrRew+4D3TBKlBKuTwiHtc/T6xfSrk2M/8nFHxgFcjMzaL32dRXDXsW\nls1EflvU8ro0er/f12Tm1pn5/Oh9wHikYyPiyZn5+szcLjNfEhHPGvWcd0TEv2bmOzJzh8x8SGY+\nJzPf33HsKyJizczcJzNnZubapZRLI+Lk6H0w+jGZuWNEfDl6H1b6ytJ2Ukq5JHofJv9C/5gPzMxd\nMvN1mbl/RET2vgPi5RFxQL+AHB0Rx2fm6LdsHdWf52HRe1Xy7tpxI+KSiHhiZu6VmQ+J3luTtu74\n/S6TzDw0My8a4zm7Z+b+/d/rYyLih9H7c+z63xtorJRyR79YbBS91aNGv2ABsDIcHL3Pj351yHOw\njKZMuSil/D56b+t5bfSuGrw0/m9FpXufc1b0Lr0dFr3PCzwzIt4XI1YrKqX8KHqfcXh89D6f8ZuI\neFNEXNlx7DOj9/0MJ0bvrVNv6Ecv6m//nf6va0fEfqWUO5e2nxHbfD56P1xfFBHfi97KWXMzc9Po\nfbD6XaWUez8r8t6I+FNEfP7e5Wn73hQR/xW9KzHbRcTTSil3VI75rv58P4jeVZY7oldyVtTM6H1Q\nu8ua/eNfEBEnRcTVEbFXWTnfqQGMkpn7ZuZT+i/K7BMRP4ve56BqV1gBmuj/3PLSiPhq/zNgTABZ\nylgfMZjaMvPDEfGkUsqOw56lhex978bPImLTUsq84U4DjHeZ+c8R8Z6IuH9E3BwR34yII/sLUACs\nNJn5+Ij4aUTsXkoZveAO49RU+szFMsnM10dvydTbI+JJ0fsOjbcMdSiAISmlfC18xgkYgv7bu7sW\nwGEcUi7+3i7Re7vUBtH7wOKbo/elcQAAQAdviwIAAJqYMh/oBgAAVi7lAgAAaKLzMxczZ84sc+bM\nWUWjwMR07rnnziulbDrsOSabmTNnltmz5wx7DBi35s69IubNm+fDrivBzJmblDmzZg17DBi3rrjy\nypg376alnn86y8WcOXPinHPOWTlTwSSRmXOHPcNkNHv2nPjVr51/oGbP3XcZ9giT1pxZs+KcM04f\n9hgwbu2y197VzNuiAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQ\nLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ\n5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACa\nUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACg\nCeUCAABoQrkAAACamDHsAQBYfosWL6lmb/r+xZ3bfvYD/10PF95ez0qpRru98PnV7Gsv2a1zng3W\nXq0zB2DicOUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJqYUEvR/uEPf6hm22yzTTVb\ne+21V8Y4nRYvXjzwtpdcckk1++xnP1vNzj///Gp22mmndR7zwAMPrGZf/OIXq1lmdu4XWDnOv/LW\navbZd32ye+Pp9VP/Zns9uZrdcFF9idvfnPitavbsjmVzIyJ+fNhe1WzaNOcYWFkW/+AL1Wz+R+o/\nb3z4f/9aza6/Z1HnMTPqf6dfNXuTarb9W/61mk0/4A2dx2TVcuUCAABoQrkAAACaUC4AAIAmlAsA\nAKAJ5QIAAGhCuQAAAJpQLgAAgCYm1PdcvO1tb6tml112WTV7xCMesTLG6fSLX/yiM1+0qL4O9DXX\nXNN6nDG/j+LLX/5yNXvLW95SzR7ykIcMPBMwuO9fduPA237ts/U14ffZ/n7V7NYF+1WzOQfW18Q/\n98RvdM4z/2WPrmYbrL1a57YwFZRb63/fL37svtXsvBvnd+53venTq9meD9u0mr3tuFd27rdLufmm\najb3iz+pZh88/BPV7J8/8vVqNuenP+qcJ9fbuDNn+blyAQAANKFcAAAATSgXAABAE8oFAADQhHIB\nAAA0oVwAAABNTKilaI866qhq9qQnPama/elPf1oZ46w006bVO992221XzZ73vOdVs9///vedxzzp\npJOq2Ve/+tVqdvTRR3fuF1g5Nl9v8CVa//ucq6vZt/54fTX70c/rS37HVRcOPM/tC+tLc1uKFiLm\nH/Qv1ez7V99SzQ7/2Rc79zvtoXtUs5y+6n9E3Oawevb6S86pZt94/L9Ws82PeFHnMdc6/uQx52L5\nuHIBAAA0oVwAAABNKBcAAEATygUAANCEcgEAADShXAAAAE1MqKVoH/WoR1WzuXPnVrMzzzyzc79j\nLdM6iFmzZnXmu+22WzWbPn16NZs9e/ZA85x8cvdSa11L0Z5zTn35N2A4XvCIB1Szj+3zj53bfu+4\n7uUpq8qSarT6Q+rntLsv7j6H3LO4vl8gYr3PfKGaHX7uz6rZ9B0fsxKmGY5pD9qlmj37a++vZoc9\n+dWd+z32kFOq2fTdnzr2YPwdVy4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoIkJtRRt\nl/XXX7+a7bfffp3bjpVPBjfccMOwRwAaWnuN+un7vHft271xR/6zi+vnisc/eLNq9pKvnlfNvnXR\nbzrH2Wid1TtzmOpy0/ry9tP3O2gVTjI+Tdvjn6rZ8zY7snPbez57fDWzFO1gXLkAAACaUC4AAIAm\nlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoIlJ8z0XdPv+978/8LYbb7xxw0mA8azruywWLV5S\nzb7zvfOr2WoP3rXzmGvM8DoXMLicVj+H7PHix3Ru+9YP/qCavfvIP1WzabMfNvZgU5QzOgAA0IRy\nAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0YSnaSeTOO++sZr/5zW8G3u9+++038LbA5HHB1fOr\n2aJLf1vNHvrMZ3bud83Vpw86EkCnfOA2nfkti+pLbJc//7G+oaVoq1y5AAAAmlAuAACAJpQLAACg\nCeUCAABoQrkAAACaUC4AAIAmLEU7ifzhD3+oZtdee+3A+91nn30G3haYPP7zp5cOewSA5TLtaQeP\n8YxjV8UYU4orFwAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhKVoJ5H3vOc9A2+70UYb\nVbO111574P0Ck8eddy0aaLsdttmk8SQAjFeuXAAAAE0oFwAAQBPKBQAA0IRyAQAANKFcAAAATSgX\nAABAE5ainWAWLaovBXnFFVcMvN+ddtqpmq2zzjoD7xeYPM785cX1sCypRv+80/1WwjQAY1v89Y8P\ne4Qpx5ULAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJrwPRcTzIIFC6rZ+eef\nX81KKZ37/djHPjbwTMDkcdl1t1ezRZecU99w4/tXoz223mRFRgIY2J0/+GVn/rC1V6tm+ZBdWo8z\nJbhyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0oVwAAABNWIp2gvnUpz410HaZ2ZnPnDlzoP0C\nk8snfnPlQNvt8pQ9q9naa/inBhiOP/3uus78pc/cqZpN22Kb1uNMCa5cAAAATSgXAABAE8oFAADQ\nhHIBAAA0oVwAAABNKBcAAEAT1gcch0op1ewXv/jFQPvcdNNNO/O11157oP0Ck8v3Tr98oO2222qD\nxpMALJuy8PZqdsXCuzq33fXggxtPgysXAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCE\npWjHofnz51ezU045ZaB9vu51r+vM11133YH2C0w8196ysJrd8IfzB9rny3d9wKDjAKyQJSceU83O\nuq17KdrnrrFW42lw5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmrAU7Th01FFHNd/n\n85///Ob7BCam6zuWoo1br69npVSjDddZfQUmAhjc5ceeVM2et+n6ndtO32Xf1uNMea5cAAAATSgX\nAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCE77kYh2655ZaBtttkk02q2YYbbjjYMMCk\n86mzr6yHWX/NadM9n1jNttxwzRUZCaBTueWGavb1uTdVszcd/4aVMQ4dXLkAAACaUC4AAIAmlAsA\nAKAJ5QIAAGhCuQAAAJpQLgAAgCYsRTskc+fOrWYnnXTSQPt8+tOfXs3WXXfdgfYJTD6XXn3rQNs9\n/fHbVrPVZnitClh5Fr3r8Go2LbKa5e5PWhnj0MG/BgAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABA\nE8oFAADQhKVoh+RrX/taNbvjjjsG2udBBx006DjAFHLeby4faLvPHfvNavb6xz6wmm2+4ZoDHQ+Y\nWspNV1ezD37uf6vZ69/0T9Vs2lYPWqGZWH6uXAAAAE0oFwAAQBPKBQAA0IRyAQAANKFcAAAATSgX\nAABAE5aiHZKNNtqo+T4f8IAHNN8nMPl88Ii9q9kRh/6ump3wkZdWM8vNAivq9kNeWM02mFF/PXz6\nK/9jZYzDgFy5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ33MxJPvvv381\n+8pXvlLN7rjjjmq2+eabr9BMwNRw8K5z6tmvP7LqBgEY4cxzrqlmLz/+jdUs191wJUzDoFy5AAAA\nmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmLEU7JBtvvHE1++lPf7oKJwEAGL59r7xw2CPQ\ngCsXAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANBEllLqYeaNETF31Y0DE9LsUsqmwx5i\nsnH+gTE596wkzj8wpur5p7NcAAAALCtviwIAAJpQLgAAgCaUCwAAoAnlAoCqzFwvM4/JzLmZeWdm\nnpmZuw57LmByy8wrMrMs5XbKsGej24xhDwDAuHZ8ROwUEQdFxFURcUBEnJaZDy2lXD3UyYDJbNeI\nmD7i/hYRcW5EfG0447CsrBYFwFJl5loRMT8inl1KOXnE4+dGxA9KKUcNbThgSsnMIyPi9RGxZSll\nwbDnoc7bogComRG9Vw4Xjnr8zojYa9WPA0xFmZkR8ZKI+LJiMf4pFwAsVSllfkScFRFHZeZWmTk9\nMw+IiD2i9xYFgFVhn4jYOnpv02ScUy4A6HJgRCyJ3uct7oqIwyLixIhYPMyhgCnlkIg4u5Ry3rAH\nYWzKBQBVpZTLSymPi4h1I+IBpZTdImK1iPjLcCcDpoLM3CwinhERnxn2LCwb5QKAMZVS7iilXJuZ\nG0XEvhFx8ljbADRwcPSumn51yHOwjKwWBUBVZu4bvReiLoqIbSPiA9H7h36vUso9w5wNmNz6H+S+\nOCJ+Xko5ZNjzsGx8zwUAXTaIiPdExP0j4uaI+GZEHKlYAKvA3hGxXfS+X4cJwpULAACgCZ+5AAAA\nmlAuAACAJpQLAACgCeUCAABowmpRwLg0c+bMMnv2nGGPAePW3LlXxLx583LYc0xGM2duUubMmjXs\nMWDcuuLKK2PevJuWev5RLoBxafbsOfGrX58z7DFg3Npz912GPcKkNWfWrDjnjNOHPQaMW7vstXc1\n87YoAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAA\naEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAA\ngCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIA\nAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4A\nAIAmZgx7AICp7Py5t1Szh8/ecJXNca9Fi5dUs+d94Zxq9pPPf2PgY6653cOr2cJrr6pmx77redXs\nwF1mDzwPTCTljluq2ZK/Xty97Vc+Xc1uP/vS+n7vWVzNNvzYhzuPOe3Bu3XmTHyuXAAAAE0oFwAA\nQBPKBQAA0IRyAQAANKFcAAAATSgXAABAE5aiBRiivf/9a9Xs4s8dVM02W3+NlTFOHPPLP1ezn3z6\nhPqG625cjZ73imd1HnP3OetXsyNe+8lq9okfX17NLEXLVLHk+1+qZoce/P5VOEnPtEc+uzM/4sGb\nVbOtX/WM+n5fdFQ1y2leKx9P/GkAAABNKBcAAEATygUAANCEcgEAADShXAAAAE0oFwAAQBPKBQAA\n0ITvuQAYoumrr17N1l9r5Zyi77x7cTV790dPG2ifP/rMq6vZbg+sfwdGRMSFV9820DGBiGn7/1s1\n++hVczu3/dOnTq1mD/vnXarZ9CM/Ws2WXPi/nce8/EWvr2ZvOeKz1Wy7t3yxmr3o5GOq2bTd/rFz\nnpw2vTNn+blyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0oVwAAABNWIoWYIje+m+PqWZrrrZy\nlki86576UrRx1YUD7fO0v8yrZjvP2rBz2xd8qmPpyrvvrEbXX3frWGPBpJfT6z/KzTjig53bPvyI\n1tNETN/5CZ35g353bjX7z/N/Vs1eu+dB1ezQJ76ymn30VY/tnGfG+0/ozFl+rlwAAABNKBcAAEAT\nygUAANCEcgEAADShXAAAAE0oFwAAQBOWogUYosMfs80qP+aG66xezY7+4GH17A0fq2YfePNH61kp\n3QNlducVT/iHBw60HTA+TX/446vZMdf8rpqdv2t9+dsjPv6LzmN+eI0XV7MZ7/xc57YsnSsXAABA\nE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCEpWgBuE/X0riP/vJR1ew/fnRRNTvrCyd2HzTr\nr3Nt+g9PrGafeO6O3fsFJo1cf5Nq9vCzflDNnrhTfXnbiIgzv/TrarbXy+rntWkPeEjnfqcyVy4A\nAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaML3XACwTHbfZuNqdtxzHl7NHjXW\n91x0+PQr9qhmM6Z7fQyIyI23rGZP/edHdG572Kd+Vc12e/dbqtman/zW2INNUc7MAABAE8oFAADQ\nhHIBAAA0oVwAAABNKBcAAEATygUAANCEpWgBWGFvPuWCgbedsd0jq9ljtps58H4BZrztI535A7/4\n6Gr2yW+cV81e88lBJ5r8XLkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCYsRQvAMrn+\n1oXV7Mdf+l59w+x+Heugf9mtmk2flmPOBVC1+lqd8YPXWr2a/XnhPa2nmRJcuQAAAJpQLgAAgCaU\nCwAAoAnlAgAAaEK5AAAAmlAuAACAJixFC8B97l60pJrt/uaO5WbvuKUazXrSUzqP+cGnbz/WWAAD\nKbf/rTP/wd8WVLMHr7Va63GmBFcuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJS9EC\ncJ+v/O7Kanbrub8caJ9nve1Jg44DsELKeb8YeNs91l+74SRThysXAABAE8oFAADQhHIBAAA0oVwA\nAABNKBcAAEATygUAANCEcgEAADThey4Appg77lpUzY54x7cH2ufRHzysmq29hn9qgOFYdNJJA2/7\nqEP2bjfIFOLKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0YX1AgCnmoC//th5ef3k9\nW23NanTwo2atwEQAK8d1v7uqM991vTWq2fRXv6v1OFOCKxcAAEATygUAANCEcgEAADShXAAAAE0o\nFwAAQBPKBQAA0ISlaAEmmUuund+Z/+TrP6uHWX/N6ZiPvKqabbD2amPOBbAyLL7o19XsuAuu69z2\nFdttVs1y3Q0HHWlKc+UCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJqwFC3AJPOiL5zT\n/YSbr6pna29QjfbddvMBJwJYeW5+5RHV7PbFpXPb2S9+cutxpjxXLgAAgCaUCwAAoAnlAgAAaEK5\nAAAAmlAuAACAJpQLAACgCUvRAkxAp154fTW74OSTB97vs17+nGq2+YZrDrxfgBVR5v21mp160Y3V\nbMd1Vu/c77RnHjzoSFS4cgEAADShXAAAAE0oFwAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABAE77n\nAmACeu8PL66HSxZ3b7zJA6rRh5/xsAEnAlh5Ttr5idXsF7feWc0+9vFXde532lYPGngmls6VCwAA\noAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABowlK0AOPUn2+4o5r99uQf1zfM7teNXn34M6rZ\nBmuvNuZcAKvaL29dWM2evvG61Wza81+zEqahiysXAABAE8oFAADQhHIBAAA0oVwAAABNKBcAAEAT\nygUAANCEpWgBxqkTzr+6Ht45f+D9Pmb2hgNvCzDe7Pf1D1SzXH2tVTgJEa5cAAAAjSgXAABAE8oF\nAADQhHIBAAA0oVwAAABNKBcAAEATlqIFmGw237Yz3nGLDVbRIABtvOmRWw17BJaRKxcAAEATygUA\nANCEcgEAADShXAAAAE0oFwAAQBPKBQAA0IRyAQAANOF7LgDGqbfu86CO7COrcBKA4brfz88a9ggs\nI1cuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAA\noAnlAgAAaEK5AAAAmlAuAACAJrKUMuwZAP5OZt4YEXOHPQeMY7NLKZsOe4jJyPkHxlQ9/ygXAABA\nE94WBQAANKFcAAAATSgXAABAE8oFAADQhHIBQFVmrpeZx2Tm3My8MzPPzMxdhz0XMLll5hWZWZZy\nO2XYs9FtxrAHAGBcOz4idoqIgyLiqog4ICJOy8yHllKuHupkwGS2a0RMH3F/i4g4NyK+NpxxWFaW\nogVgqTJzrYiYHxHPLqWcPOLxcyPiB6WUo4Y2HDClZOaREfH6iNiylLJg2PNQ521RANTMiN4rhwtH\nPX5nROy16scBpqLMzIh4SUR8WbEY/5QLAJaqlDI/Is6KiKMyc6vMnJ6ZB0TEHtF7iwLAqrBPRGwd\nvbdpMs4pFwB0OTAilkTv8xZ3RcRhEXFiRCwe5lDAlHJIRJxdSjlv2IMwNuUCgKpSyuWllMdFxLoR\n8YBSym4RsVpE/GW4kwFTQWZuFhHPiIjPDHsWlo1yAcCYSil3lFKuzcyNImLfiDh5rG0AGjg4eldN\nvzrkOVhGVosCoCoz943eC1EXRcS2EfGB6P1Dv1cp5Z5hzgZMbv0Pcl8cET8vpRwy7HlYNr7nAoAu\nG0TEeyLi/hFxc0R8MyKOVCyAVWDviNguet+vwwThygUAANCEz1wAAABNKBcAAEATygUAANCED3QD\n49LMmTPL7Nlzhj0GjFtz514R8+bNy2HPMRnNnLlJmTNr1rDHgHHriiuvjHnzblrq+Ue5AMal2bPn\nxK9+fc6wx4Bxa8/ddxn2CJPWnFmz4pwzTh/2GDBu7bLX3tXM26IAAIAmlAsAAKAJ5QIAAGhCuQAA\nAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsA\nAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkA\nAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACAJpQL\nAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCZmDHsAAMaPP1x5azU7\n7n/nVrNf/fbqanb1T7/fecx1Hr5nNTvlqP2q2cNnb9i5XwBWPVcuAACAJpQLAACgCeUCAABoQrkA\nAACaUC4AAIAmlAsAAKAJS9ECTDIL7lrUmT/+/T+vZpf88If1DRfdXY1mbPvI+nZbPKhznjt+f1Y1\n2/ull1Wz048/tJpZppapYtG7X1nN3vy+73VuO3/xkmq2zZqrVbN599S3e8k2MzuPeb8t1u3Ma2Zs\nvE41W2P3napZbtN9/pn26Ppy10tu+Gt9w4vPq2d3LaxG0//58M55JgNXLgAAgCaUCwAAoAnlAgAA\naEK5AAAAmlAuAACAJpQLAACgCeUCAABowvdcAEwyXd9jERFxyfe+Uw8327oa/eyjB1ez7TrWrr97\nUX1N/IiIp3z4l9Xs4u/WZ33jd/9UzX546J6dx4TJIvfcu5rdvvi7ndvuv8l61eyJP/pcfcO5l1Sj\ncvppncfstNVW1ei6E39WzTa//9XV7Mr//knnIa+88YPV7Ps331HNbuv4jpAX32+Darar77kAAABY\nNsoFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCEpWgBJplLzjx34G1f8rJ9q9nP/3pTNbt54d3V\n7A83zu885jHP37maPeU39eVmgYhpez2rmj14rTd1bnvb4sX1/d5vdjXL7feo73S/gzqPOaj7v3qw\n7eqLa4+dX7fldtXs9FsXVrNHvHKfMY46ublyAQAANKFcAAAATSgXAABAE8oFAADQhHIBAAA0oVwA\nAABNWIoWYJLZYOsHdua33nx1Nfvsuz452EHLknqWY7yOtc6G9WzGGgONA1NFufmaajZ/ccffy4h4\n1rvry8bmxlsOPNNEUhbVl9G+p5Rqdv81plez6f/29hWaaaJz5QIAAGhCuQAAAJpQLgAAgCaUCwAA\noAnlAgAAaEK5AAAAmrAULcAkc8XHn9OZn3rhY6rZdXcsrGZzb7mrmj145lrV7GWvPb5znrj95nq2\nen2/r35895K7MBUsfu8bq9k1dy/u3nir2Y2nmXgWf+yoavar2+rnvDftuEU1y67ltacAVy4AAIAm\nlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaML3XABMMftsf7/m+/z2H66uhwtu7d54\nrfWr0Rkn1Nfwf9j969vBVDHtkMOr2TvOu7J74wds13ia8aeMcf75j7f/z0D7vf9/vWWg7aYCVy4A\nAIAmlAsmtMwsY9y+sBKOeXDlWGu2PhYAwETibVFMdFuM+O+nRcRnRj1250o67oKI2GbkA6WUhSvp\nWAAAE4IrF0xopZTr7r1FxC1Leex5mXlZZt7d//WQkdv3rzgcmpmnZOaCzJybmQcs26H/7zj9YwEA\nTGnKBZNWZj4rIo6LiGMiYoeI+EhEfDwznz7qqf8REd+JiJ0j4tMR8d+ZucsYu1+rX0SuyszvZeYj\nmg4PADABKRdMZq+LiC+VUo4rpVxSSvloRJwQEaOXn/lWKeVT/ee8OyJ+GhGv6djvxRHx4oh4RkQ8\nPyIWRsSvMnPyL7sBANDBZy6YzLaPiM+NeuyMiPinUY+dtZT7T63ttJRy1shtMvPMiDgvIl4dEYcN\nOCtMaO/7zsX1sJTObXd86j7VzHKz0G369ntUs01/euYqnGScWrigM553z5Jqtuf6a1SzaY9+2sAj\nTXauXDDZLe2nmu6fdJb3AKUsjohzIsKVCwBgSlMumMwujIi9Rj22V0RcMOqxRy/l/oXLepDMzIjY\nKSKuXd4BAQAmE2+LYjL7QER8PTPPjYgfR8R+EfGCiNh/1PP2z8yzI+L0iHhORDwxInav7TQz3x4R\n/xsRl0bE+tF7K9ROEfFvjecHAJhQlAsmrVLKtzPz1dH7YPcxETE3Il5ZSvnuqKceHRHPjohjI+LG\niHhRKeXsjl1vGL1VpTaPiFsj4ncR8dhSym9azg8AMNEoF0wapZRvRESOeuyTEfHJMTa9rpSy33Ic\n54iIOGL5JwQAmNx85gIAAGjClQsAlsmpF15fzS46+aT6htn9OtZrn2KhNWDlWHz8ewfedp8HbVoP\nM+vZFKdcMKWVUpwdAAAa8bYoAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJq0UBcJ+7Fy2pZi/+\n8OmD7XTmrM74MVt3LPcIsAK+c+wPOvMZHWtGbvqVL1aznDZ90JEmPVcuAACAJpQLAACgCeUCAABo\nQrkAAACaUC4AAIAmlAsAAKAJS9ECcJ8vnjO3mt1+3hn1DUupRie8/187j7nJuquPORdAzaIPv66a\n/fyWhZ3bHvnIrarZtK0eNPBMU5krFwAAQBPKBQAA0IRyAQAANKFcAAAATSgXAABAE8oFAADQhHIB\nAAA04XsuAKaYu+5ZXM3e/umz6htm/fWozR/35Gr2xAdttkxzARPDkisvrGZlwW2d206buWU1y5kP\nGGieSz73k2p2d8d38EREbPqBtw50TOpcuQAAAJpQLgAAgCaUCwAAoAnlAgAAaEK5AAAAmlAuAACA\nJixFCzDFfOuPV1ezO//064H2+c4DHl7N1lht+kD7BIZnybWXV7Pjd31aNbtt0ZLO/a4+LavZ3zq2\nfcKG61Szr93YvfxtlyX/86V6OP/WerbeBvVs7fXr2W/P6B5o1gPr2WqrV6Ppez2re7+rkCsXAABA\nE8oFAADQhHIBAAA0oVwAAABNKBcAAEATygUAANCEpWgBJplFi7uXgjz0/T8ZaL/rPvwfqtmTtt1s\noH0C49O0LbapZi+7vr5M7YpYfO6p1eyn+x9WzRaV+j7Xn979OvriBXdXswUf+lQ1+/Ufb6hmj/3H\n7avZas99buc8sfa61WjaTo/t3naccOUCAABoQrkAAACaUC4AAIAmlAsAAKAJ5QIAAGhCuQAAAJqw\nFC3AJHPKBdd25kv+fN5A+z3x9U+sZhuus/pA+wS41/RH7VPNNl5tsB9Z3/XSPTrz1T701Wq2Zsd2\nTx5omqnBlQsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnlAgAAaMJStACTzOEfP6v7CWVJNVpn\npz2r2V7bzRx0JIAxlUX3VLO/Lrx7oH1Oe/7BA07DoFy5AAAAmlAuAACAJpQLAACgCeUCAABoQrkA\nAACaUC4AAIAmlAsAAKAJ33MBMAH9+vKbq9mtvzuje+Osv670oUPr33MBsDItuey31exHf1tQzZ4z\nc71qNu1R+6zQTCw/Vy4AAIAmlAsAAKAJ5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAlL0QJMQAce17Hc\nbCkD73eHmRsMvC3Ailj8if8aaLvHvWDXapbTpg86DgNy5QIAAGhCuQAAAJpQLgAAgCaUCwAAoAnl\nAgAAaEK5AAAAmrAULcAEdOOvTq2HOcbrRtPrp/7p03LAiQBWzOL5CwfbcObMtoOwQly5AAAAmlAu\nAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmLEULMAEd9JZXVLMvfvEXndu+83X7VrMHb7newDMB\nrIhv/uCCgbab9txDGk/CinDlAgAAaEK5AAAAmlAuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAm\nfM8FwAR0zDMfNlAGMExLrr6knnVs94xN1qlmuckWKzARrblyAQAANKFcAAAATSgXAABAE8oFAADQ\nhHIBAAA0oVwAAABNWIoWAIBVYtpWD6pmL7z2slU4CSuLKxcAAEATygUAANCEcgEAADShXAAAAE0o\nFwAAQBPKBQAA0ESWUoY9A8DfycwbI2LusOeAcWx2KWXTYQ8xGTn/wJiq5x/lAgAAaMLbogAAgCaU\nCwAAoAnlAgAAaEK5AKAqM9fLzGMyc25m3pmZZ2bmrsOeC5jcMvOKzCxLuZ0y7NnoNmPYAwAwrh0f\nETtFxEERcVVEHBARp2XmQ0spVw91MmAy2zUipo+4v0VEnBsRXxvOOCwrq0UBsFSZuVZEzI+IZ5dS\nTh7x+LkR8YNSylFDGw6YUjLzyIh4fURsWUpZMOx5qPO2KABqZkTvlcOFox6/MyL2WvXjAFNRZmZE\nvCQivqxYjH/KBQBLVUqZHxFnRcRRmblVZk7PzAMiYo/ovUUBYFXYJyK2jt7bNBnnlAsAuhwYEUui\n93mLuyLisIg4MSIWD3MoYEo5JCLOLqWcN+xBGJtyAUBVKeXyUsrjImLdiHhAKWW3iFgtIv4y3MmA\nqSAzN4uIZ0TEZ4Y9C8tGuQBgTKWUO0op12bmRhGxb0ScPNY2AA0cHL2rpl8d8hwsI6tFAVCVmftG\n74WoiyJi24j4QPT+od+rlHLPMGcDJrf+B7kvjoifl1IOGfY8LBvfcwFAlw0i4j0Rcf+IuDkivhkR\nRyoWwCqwd0RsF73v12GCcOUCAABowmcuAACAJpQLAACgCeUCAABoQrkAAACaUC4AAIAmlAsAAKAJ\n5QIAAGhCuQAAAJpQLgAAgCb+H8ToI1lFP2zRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1500x2000 with 15 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}